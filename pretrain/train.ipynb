{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficientnet-pytorch sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\r\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\r\n",
      "Cuda compilation tools, release 10.0, V10.0.130\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache using fc-list. This may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import models\n",
    "from dataset_generator import DatasetGenerator\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "image_size = 224\n",
    "image_resize = 256\n",
    "class_names = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'database'\n",
    "train_csv_file = 'dataset/train.txt'\n",
    "test_csv_file = 'dataset/test.txt'\n",
    "valid_csv_file = 'dataset/valid.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomOrder([\n",
    "        transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15, resample=Image.BILINEAR),\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.9, 1.0)),\n",
    "    ]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_resize),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "test_transforms = valid_transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load the datasets with DatasetGenerator\n",
    "train_dataset = DatasetGenerator(train_csv_file, image_dir, transform=train_transforms)\n",
    "image, label = next(iter(train_dataset))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load the datasets with DatasetGenerator\n",
    "test_dataset = DatasetGenerator(test_csv_file, image_dir, transform=test_transforms)\n",
    "image, label = next(iter(test_dataset))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "#TODO: Load the datasets with DatasetGenerator\n",
    "valid_dataset = DatasetGenerator(valid_csv_file, image_dir, transform=valid_transforms)\n",
    "image,label = next(iter(valid_dataset))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build and train your network\n",
    "def load_pretrained_model(arch):\n",
    "    model_func = getattr(models, arch)\n",
    "    model = model_func()\n",
    "    model.arch = arch\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_dataloader, loss_func, device):\n",
    "    #track accuracy and loss \n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad(): #deactivates requires_grad flag, disables tracking of gradients \n",
    "        for images, labels in valid_dataloader: #iterate over images and labels in valid dataset\n",
    "            images, labels = images.to(device), labels.to(device) #move a tensor to a device\n",
    "            ps = model.forward(images) #probabilities for each label\n",
    "            test_loss += loss_func(ps, labels) #take all values \n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do validation on the test set\n",
    "def test_model(model, test_loader, device):\n",
    "    #track accuracy, move to device, switch on eval mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_out = torch.FloatTensor().to(device)\n",
    "    labels_out = torch.FloatTensor().to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device) #move a tensor to a device\n",
    "            labels_out = torch.cat((labels_out,labels),0)\n",
    "            ps = model.forward(images)\n",
    "            pred_out = torch.cat((pred_out,ps),0)\n",
    "            \n",
    "    metrics = calc_roc_metrics(pred_out, labels_out)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision_recall(pred_out, labels_out):\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = []\n",
    "\n",
    "    # https://github.com/rachellea/glassboxmedicine/blob/master/2020-07-14-AUROC-AP/main.py\n",
    "    # http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "    \n",
    "    labels_out = labels_out.cpu().numpy()\n",
    "    pred_out = pred_out.cpu().numpy()\n",
    "\n",
    "    for idx, clz in enumerate(class_names):\n",
    "        clz_pred_out = pred_out[:,idx]\n",
    "        labels_list = labels_out[:,idx]\n",
    "        # TBD calculate precision and recall curve and store in precision, recall\n",
    "        precision[clz], recall[clz], _ = precision_recall_curve(y_true = labels_list,\n",
    "                                                                probas_pred = clz_pred_out)\n",
    "\n",
    "        # TBD calculate average precision score (the area under the curve)\n",
    "        average_precision.append(average_precision_score(y_true=labels_list,\n",
    "                                                         y_score = clz_pred_out))\n",
    "\n",
    "    return precision, recall, average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_roc_metrics(pred_out, labels_out):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # https://github.com/rachellea/glassboxmedicine/blob/master/2020-07-14-AUROC-AP/main.py\n",
    "    # http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "    \n",
    "    y_true = labels_out.cpu().numpy()\n",
    "    y_score = pred_out.cpu().numpy()\n",
    "\n",
    "    for idx, clz in enumerate(class_names):\n",
    "        fpr[clz], tpr[clz], _ = roc_curve(y_true[:, idx], y_score[:, idx])\n",
    "        roc_auc[clz] = auc(fpr[clz], tpr[clz])\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    \n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "    all_fpr = np.unique(np.concatenate([fpr[clz] for clz in class_names]))\n",
    "\n",
    "    # Then interpolate all ROC curves at these points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for clz in class_names:\n",
    "        mean_tpr += np.interp(all_fpr, fpr[clz], tpr[clz])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= len(class_names)\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    average_precision = average_precision_score(y_true, y_score)\n",
    "    roc_auc_mean = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    return {\n",
    "        'average_precision_score': average_precision_score(y_true, y_score),\n",
    "        'roc_auc_score': roc_auc_score(y_true, y_score),\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'roc_auc': roc_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save the checkpoint\n",
    "def save_checkpoint(checkpoint_path, model):\n",
    "    checkpoint = {\n",
    "        'arch':model.arch,\n",
    "        'metrics':model.metrics,\n",
    "        'state_dict':model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print('Saved the trained model: %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "batch_size = 64\n",
    "dataloaders = {\"train\": DataLoader(train_dataset, batch_size=batch_size, num_workers=24, shuffle=True),\n",
    "               \"test\": DataLoader(test_dataset, batch_size=batch_size, num_workers=24, shuffle=False),\n",
    "              \"valid\":DataLoader(valid_dataset, batch_size=batch_size, num_workers=24, shuffle=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DenseNet121',\n",
       " 'DenseNet169',\n",
       " 'DenseNet201',\n",
       " 'EfficientNet4',\n",
       " 'EfficientNet5',\n",
       " 'EfficientNet6',\n",
       " 'ResNet101',\n",
       " 'ResNet34',\n",
       " 'ResNet50']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_models = [m for m in dir(models) if 'Net' in m and 'Model' not in m]\n",
    "available_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'ResNet50'\n",
    "pretrained_model = load_pretrained_model(arch)\n",
    "optimizer = optim.Adam(pretrained_model.parameters(),\n",
    "                       lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "criterion = nn.BCELoss(reduction='mean')\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_path = 'checkpoints/ResNet50-24082020-091321.pth.tar'\n",
    "model_checkpoint = torch.load(ckp_path, map_location=torch.device(device))\n",
    "if model_checkpoint['arch'] != arch:\n",
    "    print('Mismatched arch: Model Checkpoint=%s vs Arch=%s'%(model_checkpoint['arch'],arch))\n",
    "\n",
    "state_dict = model_checkpoint['state_dict']\n",
    "arch = model_checkpoint['arch']\n",
    "saved_optimizer = model_checkpoint['optimizer']\n",
    "saved_scheduler = model_checkpoint['scheduler']\n",
    "\n",
    "# check the state dictionary matches\n",
    "old_state_dict = pretrained_model.state_dict()\n",
    "for k in state_dict:\n",
    "    if k not in old_state_dict:\n",
    "        print('Unexpected key %s in state_dict' % k)\n",
    "for k in old_state_dict:\n",
    "    if k not in state_dict:\n",
    "        print('Missing key %s in state_dict' % k)\n",
    "\n",
    "# TBD: load checkpoint into pretrained_model\n",
    "pretrained_model.load_state_dict(state_dict)\n",
    "optimizer.load_state_dict(saved_optimizer)\n",
    "scheduler.load_state_dict(saved_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, scheduler, dataloaders, device, epochs, checkpoint_prefix, print_every=100):\n",
    "    device = torch.device(device)\n",
    "    model.to(device)\n",
    "\n",
    "    train_loader = dataloaders['train']\n",
    "    valid_loader = dataloaders['valid']\n",
    "    test_loader = dataloaders['test']\n",
    "\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    max_acc = 0.0\n",
    "\n",
    "    # loop to train for number of epochs\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        batch_start = time.time()\n",
    "        steps = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # within each loop, iterate train_loader, and print loss\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            ps = model.forward(images)\n",
    "            loss = loss_func(ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "                valid_loss = validate(model, valid_loader, loss_func, device)\n",
    "                model.train()\n",
    "                batch_time = time.time() - batch_start\n",
    "                print(\n",
    "                    \"Epoch: {}/{}..\".format(e + 1, epochs),\n",
    "                    \"Step: {}..\".format(steps),\n",
    "                    \"Training Loss: {:.5f}..\".format(running_loss / len(train_loader)),\n",
    "                    \"Test Loss: {:.5f}..\".format(valid_loss / len(valid_loader)),\n",
    "                    \"Batch Time: {:.1f}, avg: {:.3f}\".format(batch_time, batch_time / steps)\n",
    "                )\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        valid_loss = validate(model, valid_loader, loss_func, device)\n",
    "        model.train()\n",
    "        \n",
    "        scheduler.step(valid_loss / len(valid_loader))\n",
    "\n",
    "        model.eval()\n",
    "        metrics = test_model(model, test_loader, device)\n",
    "        roc_aoc_mean = metrics['roc_auc_score']\n",
    "        average_precision_mean = metrics['average_precision_score']\n",
    "        model.train()\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        if roc_aoc_mean > max_acc:\n",
    "            max_acc = roc_aoc_mean\n",
    "            model.metrics = metrics\n",
    "            save_checkpoint('%s.pth.tar' % checkpoint_prefix, model)\n",
    "            print(\n",
    "                \"Epoch: {}/{} [save] Epoch Time={:.1f}..\".format(e + 1, epochs, epoch_time),\n",
    "                \"Average Precision: {:.3f}..\".format(average_precision_mean),\n",
    "                \"ROC: {:.3f}..\".format(roc_aoc_mean),\n",
    "                \"Batch Time: {:.1f}, avg: {:.3f}\".format(batch_time, batch_time / steps)\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"Epoch: {}/{} [----] Epoch Time={:.1f}..\".format(e + 1, epochs, epoch_time),\n",
    "                \"Average Precision: {:.3f}..\".format(average_precision_mean),\n",
    "                \"ROC: {:.3f}..\".format(roc_aoc_mean),\n",
    "                \"Batch Time: {:.1f}, avg: {:.3f}\".format(batch_time, batch_time / steps)\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "training_start = time.time()\n",
    "checkpoint_prefix = os.path.join('checkpoints','%s-%d'%(arch, training_start))\n",
    "    \n",
    "trained_model = train(pretrained_model, criterion, optimizer, scheduler, dataloaders, device, epochs, checkpoint_prefix, print_every=300)\n",
    "print('%.2f seconds taken for model training' % (time.time() - training_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trained_model.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "\n",
    "colors = ['navy', 'deeppink', 'turquoise', 'darkorange', 'cornflowerblue', 'teal']\n",
    "fpr, tpr, roc_auc = metrics['fpr'], metrics['tpr'], metrics['roc_auc']\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "idx = 0\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='Micro-average ROC (area = {0:0.2f})'.format(roc_auc[\"micro\"]),\n",
    "         color=colors[idx % len(colors)], linestyle=':', linewidth=4)\n",
    "idx += 1\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='Macro-average ROC (area = {0:0.2f})'.format(roc_auc[\"macro\"]),\n",
    "         color=colors[idx % len(colors)], linestyle=':', linewidth=4)\n",
    "idx += 1\n",
    "\n",
    "lw = 2\n",
    "# colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for clz in sorted(roc_auc, key=roc_auc.get):\n",
    "    plt.plot(fpr[clz], tpr[clz], color=colors[idx % len(colors)], lw=lw,\n",
    "             label='Class {0} (area = {1:0.2f})'.format(clz, roc_auc[clz]))\n",
    "    idx += 1\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC Curve')\n",
    "plt.legend(loc=(0, -1.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
