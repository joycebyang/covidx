{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficientnet-pytorch sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import models\n",
    "from dataset_generator import DatasetGenerator\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "image_size = 224\n",
    "\n",
    "class_to_idx = {\n",
    "    'normal': 0,\n",
    "    'pneumonia': 1,\n",
    "    'COVID-19': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'data'\n",
    "train_csv_file = 'newtrain_split.txt'\n",
    "test_csv_file = 'test_split.txt'\n",
    "valid_csv_file = 'valid_split.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomOrder([\n",
    "        transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15, resample=Image.BILINEAR),\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.9, 1.0)),\n",
    "    ]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "test_transforms = valid_transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pneumonia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "         ...,\n",
       "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
       "\n",
       "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "         ...,\n",
       "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       "\n",
       "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "         ...,\n",
       "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Load the datasets with DatasetGenerator\n",
    "train_dir = os.path.join(image_dir, 'train')\n",
    "train_dataset = DatasetGenerator(train_csv_file, train_dir, transform=train_transforms)\n",
    "image, label = next(iter(train_dataset))\n",
    "print(label)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pneumonia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4226, -0.4397, -0.4397,  ...,  0.9988,  0.8618,  0.6906],\n",
       "         [-0.3369, -0.3369, -0.3369,  ...,  0.5022,  0.4166,  0.3481],\n",
       "         [-0.2684, -0.2513, -0.2856,  ...,  0.3994,  0.3994,  0.4166],\n",
       "         ...,\n",
       "         [ 1.8893,  1.9064,  1.9578,  ...,  2.1119,  2.1975,  2.1804],\n",
       "         [ 1.9235,  1.9407,  1.9407,  ...,  2.0948,  2.1804,  2.1804],\n",
       "         [ 1.9578,  1.9749,  1.9578,  ...,  2.1119,  2.1633,  2.1633]],\n",
       "\n",
       "        [[-0.3025, -0.3200, -0.3200,  ...,  1.1506,  1.0105,  0.8354],\n",
       "         [-0.2150, -0.2150, -0.2150,  ...,  0.6429,  0.5553,  0.4853],\n",
       "         [-0.1450, -0.1275, -0.1625,  ...,  0.5378,  0.5378,  0.5553],\n",
       "         ...,\n",
       "         [ 2.0609,  2.0784,  2.1310,  ...,  2.2885,  2.3761,  2.3585],\n",
       "         [ 2.0959,  2.1134,  2.1134,  ...,  2.2710,  2.3585,  2.3585],\n",
       "         [ 2.1310,  2.1485,  2.1310,  ...,  2.2885,  2.3410,  2.3410]],\n",
       "\n",
       "        [[-0.0790, -0.0964, -0.0964,  ...,  1.3677,  1.2282,  1.0539],\n",
       "         [ 0.0082,  0.0082,  0.0082,  ...,  0.8622,  0.7751,  0.7054],\n",
       "         [ 0.0779,  0.0953,  0.0605,  ...,  0.7576,  0.7576,  0.7751],\n",
       "         ...,\n",
       "         [ 2.2740,  2.2914,  2.3437,  ...,  2.5006,  2.5877,  2.5703],\n",
       "         [ 2.3088,  2.3263,  2.3263,  ...,  2.4831,  2.5703,  2.5703],\n",
       "         [ 2.3437,  2.3611,  2.3437,  ...,  2.5006,  2.5529,  2.5529]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Load the datasets with DatasetGenerator\n",
    "test_dir = os.path.join(image_dir, 'test')\n",
    "test_dataset = DatasetGenerator(test_csv_file, test_dir, transform=test_transforms)\n",
    "image, label = next(iter(test_dataset))\n",
    "print(label)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pneumonia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1179, -2.1179, -2.1008,  ..., -2.1179, -2.1179, -2.1179],\n",
       "         [-2.1179, -2.1179, -2.0837,  ..., -2.1179, -2.1179, -2.1179],\n",
       "         [-2.1179, -2.1179, -2.0665,  ..., -2.1179, -2.1179, -2.1179],\n",
       "         ...,\n",
       "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
       "\n",
       "        [[-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
       "         [-2.0357, -2.0357, -2.0007,  ..., -2.0357, -2.0357, -2.0357],\n",
       "         [-2.0357, -2.0357, -1.9832,  ..., -2.0357, -2.0357, -2.0357],\n",
       "         ...,\n",
       "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
       "\n",
       "        [[-1.8044, -1.8044, -1.7870,  ..., -1.8044, -1.8044, -1.8044],\n",
       "         [-1.8044, -1.8044, -1.7696,  ..., -1.8044, -1.8044, -1.8044],\n",
       "         [-1.8044, -1.8044, -1.7522,  ..., -1.8044, -1.8044, -1.8044],\n",
       "         ...,\n",
       "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: Load the datasets with DatasetGenerator\n",
    "valid_dir = os.path.join(image_dir,'train')\n",
    "valid_dataset = DatasetGenerator(valid_csv_file, valid_dir, transform=valid_transforms)\n",
    "image,label = next(iter(valid_dataset))\n",
    "print(label)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build and train your network\n",
    "def load_pretrained_model(arch):\n",
    "    model_func = getattr(models, arch)\n",
    "    model = model_func()\n",
    "    model.arch = arch\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert labels to tensor\n",
    "def labels_to_tensor(labels):\n",
    "    label_indices = [class_to_idx[label] for label in labels]\n",
    "    label_indices = np.array(label_indices, int)\n",
    "    label_indices = torch.LongTensor(label_indices)\n",
    "    return label_indices\n",
    "\n",
    "labels_to_tensor(['normal', 'pneumonia', 'COVID-19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_dataloader, loss_func, device):\n",
    "    #track accuracy and loss \n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad(): #deactivates requires_grad flag, disables tracking of gradients \n",
    "        for images, labels in valid_dataloader: #iterate over images and labels in valid dataset\n",
    "            labels = labels_to_tensor(labels)\n",
    "            images, labels = images.to(device), labels.to(device) #move a tensor to a device\n",
    "            log_ps = model.forward(images) #log form of probabilities for each label\n",
    "            test_loss += loss_func(log_ps, labels).item() #.item() returns loss value as float, compare prob to actual \n",
    "            \n",
    "            ps = torch.exp(log_ps) #gets rid of log \n",
    "            equality = (labels.data == ps.max(dim=1)[1]) #takes highest probability\n",
    "            accuracy += torch.mean(equality.type(torch.FloatTensor))\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do validation on the test set\n",
    "def test_model(model, test_loader, device):\n",
    "    #track accuracy, move to device, switch on eval mode\n",
    "    accuracy = 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in iter(test_loader):\n",
    "            labels = labels_to_tensor(labels)\n",
    "            images, labels = images.to(device), labels.to(device) #move a tensor to a device\n",
    "            log_ps = model.forward(images)\n",
    "            ps = torch.exp(log_ps)\n",
    "            \n",
    "            equality = (labels.data == ps.max(dim=1)[1])\n",
    "            accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        model_accuracy = accuracy/len(test_loader)\n",
    "        model.accuracy = model_accuracy\n",
    "    \n",
    "    return model.accuracy           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save the checkpoint\n",
    "def save_checkpoint(checkpoint_path, model):\n",
    "    checkpoint = {\n",
    "        #TODO: Save the model arch, accuracy, classifier, class_to_idx\n",
    "        'arch':model.arch,\n",
    "        'accuracy':model.accuracy,\n",
    "        'class_to_idx':class_to_idx,\n",
    "        'state_dict':model.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print('Saved the trained model: %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "batch_size = 64\n",
    "dataloaders = {\"train\": DataLoader(train_dataset, batch_size=batch_size, num_workers=16, shuffle=True),\n",
    "               \"test\": DataLoader(test_dataset, batch_size=batch_size, num_workers=16, shuffle=True),\n",
    "              \"valid\":DataLoader(valid_dataset, batch_size=batch_size, num_workers=16, shuffle=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DenseNet121', 'DenseNet169', 'EfficientNet5', 'ResNet50']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_models = [m for m in dir(models) if 'Net' in m and 'Model' not in m]\n",
    "available_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to /home/ubuntu/.cache/torch/checkpoints/efficientnet-b5-b6417697.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7426bcb02f9248fda06536ad28a3463f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=122410125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "arch = 'EfficientNet5'\n",
    "pretrained_model = load_pretrained_model(arch)\n",
    "optimizer = optim.Adam(pretrained_model.get_optimizer_parameters(),\n",
    "                       lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, dataloaders, device, epochs, checkpoint_prefix, print_every=20):\n",
    "    device = torch.device(device)\n",
    "    model.to(device)\n",
    "\n",
    "    train_loader = dataloaders['train']\n",
    "    valid_loader = dataloaders['valid']\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    max_acc = 0.0\n",
    "\n",
    "    # loop to train for number of epochs\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        batch_start = time.time()\n",
    "        steps = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # within each loop, iterate train_loader, and print loss\n",
    "            label_indices = labels_to_tensor(labels)\n",
    "            images, labels = images.to(device), label_indices.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            log_ps = model.forward(images)\n",
    "            loss = loss_func(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "                valid_loss, valid_accuracy = validate(model, valid_loader, loss_func, device)\n",
    "                model.train()\n",
    "                batch_time = time.time() - batch_start\n",
    "                print(\n",
    "                    \"Epoch: {}/{}..\".format(e + 1, epochs),\n",
    "                    \"Step: {}..\".format(steps),\n",
    "                    \"Training Loss: {:.3f}..\".format(running_loss / len(train_loader)),\n",
    "                    \"Test Loss: {:.3f}..\".format(valid_loss / len(valid_loader)),\n",
    "                    \"Test Accuracy: {:.3f}..\".format(valid_accuracy / len(valid_loader)),\n",
    "                    \"Batch Time: {:.3f}, avg: {:.3f}\".format(batch_time, batch_time / steps)\n",
    "                )\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss, valid_accuracy = validate(model, valid_loader, loss_func, device)\n",
    "        model.train()\n",
    "        epoch_time = time.time() - epoch_start\n",
    "\n",
    "        if valid_accuracy > max_acc:\n",
    "            max_acc = valid_accuracy\n",
    "            model.accuracy = valid_accuracy\n",
    "            save_checkpoint('%s.pth.tar' % checkpoint_prefix, model)\n",
    "            print ('Epoch [{}] [save] Accuracy={:.3f} time: {:.3f}, avg: {:.3f}'\n",
    "                   .format(e + 1, valid_accuracy / len(valid_loader), epoch_time, epoch_time / (e + 1)))\n",
    "        else:\n",
    "            print ('Epoch [{}] [----] Accuracy={:.3f} time: {:.3f}, avg: {:.3f}'\n",
    "                   .format(e + 1, valid_accuracy / len(valid_loader), epoch_time, epoch_time / (e + 1)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2.. Step: 20.. Training Loss: 0.111.. Test Loss: 1.050.. Test Accuracy: 0.594.. Batch Time: 93.928, avg: 4.696\n",
      "Epoch: 1/2.. Step: 40.. Training Loss: 0.219.. Test Loss: 1.030.. Test Accuracy: 0.596.. Batch Time: 155.609, avg: 3.890\n",
      "Epoch: 1/2.. Step: 60.. Training Loss: 0.324.. Test Loss: 1.002.. Test Accuracy: 0.635.. Batch Time: 218.787, avg: 3.646\n",
      "Epoch: 1/2.. Step: 80.. Training Loss: 0.427.. Test Loss: 0.984.. Test Accuracy: 0.629.. Batch Time: 282.833, avg: 3.535\n",
      "Epoch: 1/2.. Step: 100.. Training Loss: 0.527.. Test Loss: 0.962.. Test Accuracy: 0.689.. Batch Time: 347.452, avg: 3.475\n",
      "Epoch: 1/2.. Step: 120.. Training Loss: 0.625.. Test Loss: 0.944.. Test Accuracy: 0.728.. Batch Time: 411.659, avg: 3.430\n",
      "Epoch: 1/2.. Step: 140.. Training Loss: 0.721.. Test Loss: 0.925.. Test Accuracy: 0.785.. Batch Time: 475.467, avg: 3.396\n",
      "Epoch: 1/2.. Step: 160.. Training Loss: 0.816.. Test Loss: 0.921.. Test Accuracy: 0.797.. Batch Time: 538.951, avg: 3.368\n",
      "Epoch: 1/2.. Step: 180.. Training Loss: 0.909.. Test Loss: 0.913.. Test Accuracy: 0.822.. Batch Time: 594.882, avg: 3.305\n",
      "Saved the trained model: checkpoints/EfficientNet5-1597702792.pth.tar\n",
      "Epoch [1] [save] Accuracy=0.787 time: 643.774, avg: 643.774\n",
      "Epoch: 2/2.. Step: 20.. Training Loss: 0.090.. Test Loss: 0.898.. Test Accuracy: 0.806.. Batch Time: 102.090, avg: 5.105\n",
      "Epoch: 2/2.. Step: 40.. Training Loss: 0.177.. Test Loss: 0.900.. Test Accuracy: 0.805.. Batch Time: 169.886, avg: 4.247\n",
      "Epoch: 2/2.. Step: 60.. Training Loss: 0.264.. Test Loss: 0.881.. Test Accuracy: 0.812.. Batch Time: 232.148, avg: 3.869\n",
      "Epoch: 2/2.. Step: 80.. Training Loss: 0.349.. Test Loss: 0.885.. Test Accuracy: 0.800.. Batch Time: 294.917, avg: 3.686\n",
      "Epoch: 2/2.. Step: 100.. Training Loss: 0.434.. Test Loss: 0.884.. Test Accuracy: 0.786.. Batch Time: 359.575, avg: 3.596\n",
      "Epoch: 2/2.. Step: 120.. Training Loss: 0.518.. Test Loss: 0.878.. Test Accuracy: 0.781.. Batch Time: 421.538, avg: 3.513\n",
      "Epoch: 2/2.. Step: 140.. Training Loss: 0.601.. Test Loss: 0.864.. Test Accuracy: 0.788.. Batch Time: 486.506, avg: 3.475\n",
      "Epoch: 2/2.. Step: 160.. Training Loss: 0.682.. Test Loss: 0.855.. Test Accuracy: 0.795.. Batch Time: 551.256, avg: 3.445\n",
      "Epoch: 2/2.. Step: 180.. Training Loss: 0.762.. Test Loss: 0.856.. Test Accuracy: 0.761.. Batch Time: 608.703, avg: 3.382\n",
      "Epoch [2] [----] Accuracy=0.779 time: 1300.445, avg: 650.223\n",
      "1301.88 seconds taken for model training\n"
     ]
    }
   ],
   "source": [
    "#device = 'cpu'\n",
    "epochs = 2\n",
    "training_start = time.time()\n",
    "checkpoint_prefix = os.path.join('checkpoints','%s-%d'%(arch, training_start))\n",
    "    \n",
    "trained_model = train(pretrained_model, criterion, optimizer, dataloaders, device, epochs, checkpoint_prefix, print_every=20)\n",
    "print('%.2f seconds taken for model training' % (time.time() - training_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7373)\n"
     ]
    }
   ],
   "source": [
    "test_loader = dataloaders['test']\n",
    "test_accuracy = test_model(trained_model, test_loader, device)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
