{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficientnet-pytorch sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "import models\n",
    "from dataset_generator import DatasetGenerator\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "# this is an enhancement to first resize to larger image and then crop\n",
    "image_resize = 256\n",
    "image_size = 224\n",
    "\n",
    "class_to_idx = {\n",
    "    'normal': 0,\n",
    "    'pneumonia': 1,\n",
    "    'COVID-19': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "0.5.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'data'\n",
    "# we will use train/test split only to get more COVID-19 data\n",
    "train_csv_file = 'train_split.txt'\n",
    "test_csv_file = 'test_split.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomOrder([\n",
    "        transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15, resample=Image.BILINEAR),\n",
    "        transforms.RandomResizedCrop(image_size, scale=(0.9, 1.0)),\n",
    "    ]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_resize),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(image_dir, 'train')\n",
    "train_dataset = DatasetGenerator(train_csv_file, train_dir, transform=train_transforms)\n",
    "image, label = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(image_dir, 'test')\n",
    "test_dataset = DatasetGenerator(test_csv_file, test_dir, transform=test_transforms)\n",
    "image, label = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(arch):\n",
    "    model_func = getattr(models, arch)\n",
    "    model = model_func()\n",
    "    model.arch = arch\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert labels to tensor\n",
    "def labels_to_tensor(labels):\n",
    "    label_indices = [class_to_idx[label] for label in labels]\n",
    "    label_indices = np.array(label_indices, int)\n",
    "    label_indices = torch.LongTensor(label_indices)\n",
    "    return label_indices\n",
    "\n",
    "labels_to_tensor(['normal', 'pneumonia', 'COVID-19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_dataloader, loss_func, device):\n",
    "    #track accuracy and loss \n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad(): #deactivates requires_grad flag, disables tracking of gradients \n",
    "        for images, labels in valid_dataloader: #iterate over images and labels in valid dataset\n",
    "            labels = labels_to_tensor(labels)\n",
    "            images, labels = images.to(device), labels.to(device) #move a tensor to a device\n",
    "            log_ps = model.forward(images) #log form of probabilities for each label\n",
    "            test_loss += loss_func(log_ps, labels).item() #.item() returns loss value as float, compare prob to actual \n",
    "            \n",
    "            ps = torch.exp(log_ps) #gets rid of log \n",
    "            equality = (labels.data == ps.max(dim=1)[1]) #takes highest probability\n",
    "            accuracy += torch.mean(equality.type(torch.FloatTensor))\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do validation on the test set\n",
    "def test_model(model, test_loader, device):\n",
    "    #track accuracy, move to device, switch on eval mode\n",
    "    accuracy = 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in iter(test_loader):\n",
    "            labels = labels_to_tensor(labels)\n",
    "            images, labels = images.to(device), labels.to(device) #move a tensor to a device\n",
    "            log_ps = model.forward(images)\n",
    "            ps = torch.exp(log_ps)\n",
    "            \n",
    "            equality = (labels.data == ps.max(dim=1)[1])\n",
    "            accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        model_accuracy = accuracy/len(test_loader)\n",
    "        model.accuracy = model_accuracy\n",
    "    \n",
    "    return model.accuracy           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the checkpoint\n",
    "def save_checkpoint(checkpoint_path, model):\n",
    "    checkpoint = {\n",
    "        # Save the model arch, accuracy, class_to_idx\n",
    "        'arch':model.arch,\n",
    "        'accuracy':model.accuracy,\n",
    "        'class_to_idx':class_to_idx,\n",
    "        'state_dict':model.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print('Saved the trained model: %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7493095656540296, 2.550329428989751, 27.594059405940595]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_cnt = [0, 0, 0]\n",
    "train_labels = [] \n",
    "\n",
    "# TBD shuffle the training data \n",
    "# TBD this is best done inside the DatasetGenerator class\n",
    "# train_dataset.csv_df = train_dataset.csv_df.sample(frac=1)\n",
    "for label in train_dataset.csv_df[2]:\n",
    "    train_label_cnt[class_to_idx[label]] += 1\n",
    "    train_labels.append(class_to_idx[label])\n",
    "    \n",
    "train_num_samples = sum(train_label_cnt)\n",
    "train_class_weights = [train_num_samples/train_label_cnt[i] for i in range(len(train_label_cnt))]\n",
    "train_weights = [train_class_weights[train_labels[i]] for i in range(int(train_num_samples))] \n",
    "\n",
    "# TBD create WeightedRandomSampler to balance the training data set\n",
    "train_sampler = WeightedRandomSampler(torch.DoubleTensor(train_weights), int(train_num_samples))\n",
    "\n",
    "#train_dataset.csv_df.head(20)\n",
    "train_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the image datasets and the transforms, define the dataloaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=16, shuffle=False, sampler=train_sampler)\n",
    "\n",
    "dataloaders = {\"train\": train_loader,\n",
    "               \"test\": DataLoader(test_dataset, batch_size=batch_size, num_workers=16, shuffle=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DenseNet121',\n",
       " 'DenseNet169',\n",
       " 'DenseNet201',\n",
       " 'EfficientNet4',\n",
       " 'EfficientNet5',\n",
       " 'EfficientNet6',\n",
       " 'ResNet101',\n",
       " 'ResNet34',\n",
       " 'ResNet50']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_models = [m for m in dir(models) if 'Net' in m and 'Model' not in m]\n",
    "available_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /home/ubuntu/.cache/torch/checkpoints/densenet169-b2777c0a.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc611989bc94d9c96b0a79ccabb891c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57365526.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "arch = 'DenseNet169'\n",
    "pretrained_model = load_pretrained_model(arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -ltrh ../pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_prior_weights(pretrained_model, state_dict, prefix='module.'):\n",
    "    old_state_dict = pretrained_model.state_dict()\n",
    "    new_state_dict = state_dict\n",
    "\n",
    "    if prefix is not None:\n",
    "        new_state_dict = OrderedDict()\n",
    "        # make sure the keys of the state dict match those of old_state_dict\n",
    "        for k in state_dict:\n",
    "            short_key = k.replace(prefix, '')\n",
    "            # make sure the shape of the weight tensors matches\n",
    "            if state_dict[k].shape != old_state_dict[short_key].shape:\n",
    "                print('Unmatched key {} in state_dict: {} vs. {}'.format(short_key, \n",
    "                                                                         state_dict[k].shape,\n",
    "                                                                         old_state_dict[short_key].shape))\n",
    "            else:\n",
    "                new_state_dict[short_key] = state_dict[k]\n",
    "\n",
    "    for k in new_state_dict:\n",
    "        if k not in old_state_dict:\n",
    "            print('Unexpected key %s in new_state_dict' % k)\n",
    "\n",
    "    for k in old_state_dict:\n",
    "        if k not in new_state_dict:\n",
    "            print('Missing key %s in old_state_dict' % k)\n",
    "\n",
    "    return new_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TBD this is to load previously saved checkpoints from pretraining\n",
    "# ckp_path = '../pretrain/DenseNet169-17082020-063151.pth.tar'\n",
    "# model_checkpoint = torch.load(ckp_path, map_location=torch.device(device))\n",
    "# state_dict = model_checkpoint['state_dict']\n",
    "\n",
    "# # TBD this step is for converting the variable names from pretraining\n",
    "# # TBD so it is not necessary when loading saved checkpoints from previous txfer learning\n",
    "# new_state_dict = convert_prior_weights(pretrained_model, state_dict)\n",
    "\n",
    "# pretrained_model.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(pretrained_model.get_optimizer_parameters(),\n",
    "                       lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, dataloaders, device, epochs, checkpoint_prefix, print_every=20):\n",
    "    device = torch.device(device)\n",
    "    model.to(device)\n",
    "\n",
    "    train_loader = dataloaders['train']\n",
    "    test_loader = dataloaders['test']\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    max_acc = 0.0\n",
    "\n",
    "    # loop to train for number of epochs\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        batch_start = time.time()\n",
    "        steps = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # within each loop, iterate train_loader, and print loss\n",
    "            label_indices = labels_to_tensor(labels)\n",
    "            images, labels = images.to(device), label_indices.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            log_ps = model.forward(images)\n",
    "            loss = loss_func(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "                valid_loss, valid_accuracy = validate(model, test_loader, loss_func, device)\n",
    "                model.train()\n",
    "                batch_time = time.time() - batch_start\n",
    "                print(\n",
    "                    \"Epoch: {}/{}..\".format(e + 1, epochs),\n",
    "                    \"Step: {}..\".format(steps),\n",
    "                    \"Training Loss: {:.3f}..\".format(running_loss / len(train_loader)),\n",
    "                    \"Test Loss: {:.3f}..\".format(valid_loss / len(test_loader)),\n",
    "                    \"Test Accuracy: {:.3f}..\".format(valid_accuracy / len(test_loader)),\n",
    "                    \"Batch Time: {:.3f}, avg: {:.3f}\".format(batch_time, batch_time / steps)\n",
    "                )\n",
    "\n",
    "        model.eval()\n",
    "        test_accuracy = test_model(model, test_loader, device)\n",
    "        model.train()\n",
    "        epoch_time = time.time() - epoch_start\n",
    "\n",
    "        if test_accuracy > max_acc:\n",
    "            max_acc = test_accuracy\n",
    "            model.accuracy = test_accuracy\n",
    "            save_checkpoint('%s.pth.tar' % checkpoint_prefix, model)\n",
    "            print ('Epoch [{}] [save] Accuracy={:.3f} time: {:.3f}, avg: {:.3f}'\n",
    "                   .format(e + 1, test_accuracy, epoch_time, epoch_time / (e + 1)))\n",
    "        else:\n",
    "            print ('Epoch [{}] [----] Accuracy={:.3f} time: {:.3f}, avg: {:.3f}'\n",
    "                   .format(e + 1, test_accuracy, epoch_time, epoch_time / (e + 1)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2.. Step: 20.. Training Loss: 0.096.. Test Loss: 0.985.. Test Accuracy: 0.750.. Batch Time: 287.100, avg: 14.355\n",
      "Epoch: 1/2.. Step: 40.. Training Loss: 0.191.. Test Loss: 0.967.. Test Accuracy: 0.778.. Batch Time: 379.257, avg: 9.481\n",
      "Epoch: 1/2.. Step: 60.. Training Loss: 0.283.. Test Loss: 0.956.. Test Accuracy: 0.778.. Batch Time: 481.504, avg: 8.025\n",
      "Epoch: 1/2.. Step: 80.. Training Loss: 0.373.. Test Loss: 0.940.. Test Accuracy: 0.779.. Batch Time: 619.689, avg: 7.746\n",
      "Epoch: 1/2.. Step: 100.. Training Loss: 0.461.. Test Loss: 0.901.. Test Accuracy: 0.802.. Batch Time: 780.732, avg: 7.807\n",
      "Epoch: 1/2.. Step: 120.. Training Loss: 0.547.. Test Loss: 0.884.. Test Accuracy: 0.804.. Batch Time: 874.772, avg: 7.290\n",
      "Epoch: 1/2.. Step: 140.. Training Loss: 0.631.. Test Loss: 0.879.. Test Accuracy: 0.788.. Batch Time: 988.440, avg: 7.060\n",
      "Epoch: 1/2.. Step: 160.. Training Loss: 0.713.. Test Loss: 0.843.. Test Accuracy: 0.802.. Batch Time: 1098.013, avg: 6.863\n",
      "Epoch: 1/2.. Step: 180.. Training Loss: 0.794.. Test Loss: 0.858.. Test Accuracy: 0.762.. Batch Time: 1239.233, avg: 6.885\n",
      "Epoch: 1/2.. Step: 200.. Training Loss: 0.874.. Test Loss: 0.835.. Test Accuracy: 0.781.. Batch Time: 1348.176, avg: 6.741\n",
      "Saved the trained model: checkpoints/DenseNet169-1597877428.pth.tar\n",
      "Epoch [1] [save] Accuracy=0.767 time: 1394.757, avg: 1394.757\n",
      "Epoch: 2/2.. Step: 20.. Training Loss: 0.076.. Test Loss: 0.750.. Test Accuracy: 0.821.. Batch Time: 262.592, avg: 13.130\n",
      "Epoch: 2/2.. Step: 40.. Training Loss: 0.151.. Test Loss: 0.773.. Test Accuracy: 0.798.. Batch Time: 390.210, avg: 9.755\n",
      "Epoch: 2/2.. Step: 60.. Training Loss: 0.224.. Test Loss: 0.766.. Test Accuracy: 0.792.. Batch Time: 491.434, avg: 8.191\n",
      "Epoch: 2/2.. Step: 80.. Training Loss: 0.295.. Test Loss: 0.752.. Test Accuracy: 0.795.. Batch Time: 590.370, avg: 7.380\n",
      "Epoch: 2/2.. Step: 100.. Training Loss: 0.366.. Test Loss: 0.718.. Test Accuracy: 0.807.. Batch Time: 750.210, avg: 7.502\n",
      "Epoch: 2/2.. Step: 120.. Training Loss: 0.435.. Test Loss: 0.732.. Test Accuracy: 0.785.. Batch Time: 880.322, avg: 7.336\n",
      "Epoch: 2/2.. Step: 140.. Training Loss: 0.503.. Test Loss: 0.729.. Test Accuracy: 0.786.. Batch Time: 974.765, avg: 6.963\n",
      "Epoch: 2/2.. Step: 160.. Training Loss: 0.571.. Test Loss: 0.716.. Test Accuracy: 0.783.. Batch Time: 1105.441, avg: 6.909\n",
      "Epoch: 2/2.. Step: 180.. Training Loss: 0.637.. Test Loss: 0.702.. Test Accuracy: 0.790.. Batch Time: 1221.186, avg: 6.784\n",
      "Epoch: 2/2.. Step: 200.. Training Loss: 0.703.. Test Loss: 0.707.. Test Accuracy: 0.786.. Batch Time: 1350.242, avg: 6.751\n",
      "Saved the trained model: checkpoints/DenseNet169-1597877428.pth.tar\n",
      "Epoch [2] [save] Accuracy=0.789 time: 2801.944, avg: 1400.972\n",
      "2802.42 seconds taken for model training\n"
     ]
    }
   ],
   "source": [
    "#device = 'cpu'\n",
    "epochs = 2\n",
    "training_start = time.time()\n",
    "checkpoint_prefix = os.path.join('checkpoints','%s-%d'%(arch, training_start))\n",
    "    \n",
    "trained_model = train(pretrained_model, criterion, optimizer, dataloaders, device, epochs, checkpoint_prefix, print_every=20)\n",
    "print('%.2f seconds taken for model training' % (time.time() - training_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = dataloaders['test']\n",
    "test_accuracy = test_model(trained_model, test_loader, device)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
